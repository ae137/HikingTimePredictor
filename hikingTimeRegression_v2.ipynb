{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHp3M9ZmrIxj"
   },
   "source": [
    "# Predict hiking times based on GPX tracks\n",
    "\n",
    "We attempt to predict the walking times and durations for hikes based on GPX files using recurrent neural networks. Using personal GPX records as input, the outputs are personalized as well.\n",
    "\n",
    "We use the `tf.keras` API, see [this guide](https://www.tensorflow.org/guide/keras) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1rRo8oNqZ-Rj"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import gpx_stats\n",
    "import utils\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFh9ne3FZ-On"
   },
   "source": [
    "### Load data\n",
    "Load the dataset that was prepared by running the following command in a shell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9kxxgzvzlyz"
   },
   "source": [
    "`python prepareData.py ~/GPX-Tracks Wandern`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9kxxgzvzlyz"
   },
   "outputs": [],
   "source": [
    "train_dataset_file = 'hiking_data_training.hdf5'\n",
    "test_dataset_file = 'hiking_data_test.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nslsRLh7Zss4"
   },
   "source": [
    "Convert data to a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf5_to_dict(file_name):\n",
    "    hdf5_data = h5py.File(file_name, 'r')\n",
    "    hdf5_data_dict = {}\n",
    "    for name in gpx_stats.GpxSegmentStats.getHeader():\n",
    "        if name == 'Path':\n",
    "            hdf5_data_dict[name] = [gpx_stats.PathFeature(data) for data in hdf5_data[name]]\n",
    "        else:\n",
    "            hdf5_data_dict[name] = hdf5_data[name][...]\n",
    "\n",
    "    hdf5_data.close()\n",
    "    return hdf5_data_dict\n",
    "\n",
    "train_hdf5_data_dict = read_hdf5_to_dict(train_dataset_file)\n",
    "test_hdf5_data_dict = read_hdf5_to_dict(test_dataset_file)\n",
    "\n",
    "path_features_shape = train_hdf5_data_dict['Path'][0].shape\n",
    "    \n",
    "train_dataset = pd.DataFrame.from_dict(train_hdf5_data_dict)\n",
    "test_dataset = pd.DataFrame.from_dict(test_hdf5_data_dict)\n",
    "\n",
    "train_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Db7Auq1yXUvh"
   },
   "source": [
    "### Split features from labels\n",
    "\n",
    "Separate the target value, or \"label\", from the features. This label is the value that we will train the model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2sluJdCW7jN"
   },
   "outputs": [],
   "source": [
    "label_columns = ['MovingTime']\n",
    "drop_columns = [\"StoppedTime\", \"Duration\"]\n",
    "train_dataset.drop(columns=drop_columns, inplace=True)\n",
    "test_dataset.drop(columns=drop_columns, inplace=True)\n",
    "\n",
    "train_labels_data = []\n",
    "test_labels_data = []\n",
    "\n",
    "for col_name in label_columns:\n",
    "    train_labels_data.append(train_dataset.pop(col_name))\n",
    "    test_labels_data.append(test_dataset.pop(col_name))\n",
    "\n",
    "train_labels = pd.concat(train_labels_data, axis=1)\n",
    "train_labels.sort_index(inplace=True)\n",
    "test_labels = pd.concat(test_labels_data, axis=1)\n",
    "test_labels.sort_index(inplace=True)\n",
    "\n",
    "def convert_paths_to_array(path_features):\n",
    "    return np.array([path_data.data for path_data in path_features])\n",
    "\n",
    "train_paths = train_dataset.pop('Path')\n",
    "test_paths = test_dataset.pop('Path')\n",
    "train_paths_as_array = gpx_stats.convert_paths_to_array(train_paths)\n",
    "test_paths_as_array = gpx_stats.convert_paths_to_array(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Properly fix NaN issue in elevation!!!\n",
    "# Quick and dirty fix: Set NaN values to 0\n",
    "train_paths_as_array = np.nan_to_num(train_paths_as_array, copy=False)\n",
    "test_paths_as_array = np.nan_to_num(test_paths_as_array, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SWtkIjhrZwa"
   },
   "source": [
    "## The model\n",
    "\n",
    "### Build the model\n",
    "\n",
    "Let's build our model. It consists of a few 1d convolutional layers, following by two LSTM layers and two dense layers. The 1d convolutional layers provide some preprocessing of the tracks and are numerially very cheap. As we only have few tracks available, reducing the number of parameters in the model helps to avoid overfitting. The last fully connected layer outputs duration, moving time and stopped time. The model building steps are wrapped in a function, `build_model`, for convencience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cGbPb-PHGbhs"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "def build_model():\n",
    "    path_inputs = layers.Input(shape=path_features_shape, name='PathInputs')\n",
    "    conv1 = layers.Conv1D(filters=6, kernel_size=3, padding='same', activation=tf.nn.relu)(path_inputs)\n",
    "    conv2 = layers.Conv1D(filters=12, kernel_size=3, padding='same', activation=tf.nn.relu)(conv1)\n",
    "    bn1 = layers.BatchNormalization()(conv2)\n",
    "    conv3 = layers.Conv1D(filters=24, kernel_size=3, padding='same', activation=tf.nn.relu)(bn1)\n",
    "    conv4 = layers.Conv1D(filters=6, kernel_size=3, padding='same', activation=tf.nn.relu)(conv3)\n",
    "    bn2 = layers.BatchNormalization()(conv4)\n",
    "    \n",
    "    lstm1 = layers.LSTM(16, return_sequences=True)(bn2)\n",
    "    dropout = layers.Dropout(0.25)(lstm1)\n",
    "    lstm2 = layers.LSTM(16, return_sequences=False)(dropout)\n",
    "    dropout2 = layers.Dropout(0.25)(lstm2)\n",
    "    dense1 = layers.Dense(32, activation=tf.nn.relu)(dropout2)\n",
    "\n",
    "    outputs = layers.Dense(len(train_labels.keys()), activation=None)(dense1)\n",
    "    \n",
    "    model = models.Model(inputs=path_inputs, outputs=outputs)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', \n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vt6W50qGsJAL"
   },
   "source": [
    "\n",
    "Now try out the model. Take a batch of `4` examples from the training data and call `model.predict` on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-d-gBaVtGTSC"
   },
   "outputs": [],
   "source": [
    "example_batch = train_paths_as_array[:4]\n",
    "example_result = model.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0-qWCsh6DlyH"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "Train the model for up to 500 epochs with the training set, and record the training and validation accuracy in the `history` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sD7qHCmNIOY0"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "batch_size = 64\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                                 patience=20, min_lr=0.01*learning_rate)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40, verbose=1, \n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "callbacks = [reduce_lr, early_stopping]\n",
    "\n",
    "\n",
    "history = model.fit(train_paths_as_array, \n",
    "                    train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(test_paths_as_array, test_labels),\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQm3pc0FYPQB"
   },
   "source": [
    "Visualize the model's training progress using the stats stored in the `history` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Xj91b-dymEy"
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6XriGbVPh2t"
   },
   "outputs": [],
   "source": [
    "utils.plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ft603OzXuEZC"
   },
   "source": [
    "### Make predictions\n",
    "\n",
    "Finally, predict walking time values using data in the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xe7RXH3N3CWU"
   },
   "outputs": [],
   "source": [
    "compute_standard_walking_time_vectorized = np.vectorize(utils.compute_standard_walking_time)\n",
    "\n",
    "standard_estimate_walking_time = compute_standard_walking_time_vectorized(test_dataset['Length2d'].values,\n",
    "                                                                          test_dataset['TotalUphill'].values,\n",
    "                                                                          test_dataset['TotalDownhill'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xe7RXH3N3CWU"
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_paths_as_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xe7RXH3N3CWU"
   },
   "outputs": [],
   "source": [
    "for i, label_col_name in enumerate(label_columns):\n",
    "    utils.scatter_plot(test_labels[label_col_name],\n",
    "                       test_predictions[:, i],\n",
    "                       label_col_name,\n",
    "                       max_val=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OrkHGKZcusUo"
   },
   "source": [
    "It looks like our model predicts durations and moving times reasonably well, as the results should be as close to the diagonal as possible. There are interesting gaps in the plots at low times. Let's take a look at the error distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label_col_name in enumerate(label_columns):\n",
    "    utils.plot_error_hist(test_labels[label_col_name], test_predictions[:, i], label_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9_kI6MHu1UU"
   },
   "source": [
    "It's not quite gaussian, but we might expect that because the number of samples is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_paths_as_array, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9_kI6MHu1UU"
   },
   "source": [
    "Export model for use in inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_hikingTimePrediction_recurrent.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgGQuV-yqYZH"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook presents the training of an algorithm for predicting moving and stopping times as well as total duration for hiking (but it can also be applied to many other outdoor activities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "basic_regression.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
