{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHp3M9ZmrIxj"
   },
   "source": [
    "# Predict hiking times based on GPX tracks\n",
    "\n",
    "We attempt to predict the walking times and durations for hikes based on GPX files using recurrent neural networks. Using personal GPX records as input, the outputs are personalized as well.\n",
    "\n",
    "We use the `tf.keras` API, see [this guide](https://www.tensorflow.org/guide/keras) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1rRo8oNqZ-Rj"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import gpx_stats\n",
    "import utils\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFh9ne3FZ-On"
   },
   "source": [
    "### Load data\n",
    "\n",
    "Load the dataset that was prepared by running the following command in a shell:\n",
    "\n",
    "`run prepareData.py '~/GPX-Tracks' 'Wandern'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9kxxgzvzlyz"
   },
   "outputs": [],
   "source": [
    "train_dataset_file = 'hiking_data_training.hdf5'\n",
    "test_dataset_file = 'hiking_data_test.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nslsRLh7Zss4"
   },
   "source": [
    "Convert data to a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf5_to_dict(file_name):\n",
    "    hdf5_data = h5py.File(file_name, 'r')\n",
    "    hdf5_data_dict = {}\n",
    "    for name in gpx_stats.GpxSegmentStats.get_header():\n",
    "        if name == 'Path':\n",
    "            hdf5_data_dict[name] = [gpx_stats.PathFeature(data) for data in hdf5_data[name]]\n",
    "        else:\n",
    "            hdf5_data_dict[name] = hdf5_data[name][...]\n",
    "\n",
    "    hdf5_data.close()\n",
    "    return hdf5_data_dict\n",
    "\n",
    "train_hdf5_data_dict = read_hdf5_to_dict(train_dataset_file)\n",
    "test_hdf5_data_dict = read_hdf5_to_dict(test_dataset_file)\n",
    "\n",
    "path_features_shape = train_hdf5_data_dict['Path'][0].shape\n",
    "    \n",
    "train_dataset = pd.DataFrame.from_dict(train_hdf5_data_dict)\n",
    "test_dataset = pd.DataFrame.from_dict(test_hdf5_data_dict)\n",
    "\n",
    "train_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Db7Auq1yXUvh"
   },
   "source": [
    "### Split features from labels\n",
    "\n",
    "Separate the target value, or \"label\", from the features. This label is the value that we will train the model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2sluJdCW7jN"
   },
   "outputs": [],
   "source": [
    "data_columns = [\"Path\"]\n",
    "label_columns = ['MovingTime']\n",
    "train_labels_data = []\n",
    "test_labels_data = []\n",
    "\n",
    "train_data = train_dataset[data_columns]\n",
    "train_labels = train_dataset[label_columns]\n",
    "\n",
    "test_data = test_dataset[data_columns]\n",
    "test_labels = test_dataset[label_columns]\n",
    "\n",
    "train_paths_as_array = gpx_stats.convert_paths_to_array(train_data[\"Path\"])\n",
    "test_paths_as_array = gpx_stats.convert_paths_to_array(test_data[\"Path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter paths with `NaN` entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nan_mask = np.any(np.isnan(train_paths_as_array), axis=(1, 2))\n",
    "test_nan_mask = np.any(np.isnan(test_paths_as_array), axis=(1, 2))\n",
    "\n",
    "train_paths_as_array = train_paths_as_array[~train_nan_mask]\n",
    "train_labels = train_labels[~train_nan_mask]\n",
    "\n",
    "test_paths_as_array = test_paths_as_array[~test_nan_mask]\n",
    "test_labels = test_labels[~test_nan_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SWtkIjhrZwa"
   },
   "source": [
    "## The model\n",
    "\n",
    "### Build the model\n",
    "\n",
    "Let's build our model. It consists of a few 1d convolutional layers, following by two LSTM layers and two dense layers. The 1d convolutional layers provide some preprocessing of the tracks and are numerially very cheap. As we only have few tracks available, reducing the number of parameters in the model helps to avoid overfitting. The last fully connected layer outputs duration, moving time and stopped time. The model building steps are wrapped in a function, `build_model`, for convencience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cGbPb-PHGbhs"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "\n",
    "def build_model():\n",
    "    path_inputs = layers.Input(shape=path_features_shape, name='PathInputs')\n",
    "    conv1 = layers.Conv1D(filters=6, kernel_size=3, padding='same', activation=tf.nn.relu)(path_inputs)\n",
    "    conv2 = layers.Conv1D(filters=12, kernel_size=3, padding='same', activation=tf.nn.relu)(conv1)\n",
    "    bn1 = layers.BatchNormalization()(conv2)\n",
    "    conv3 = layers.Conv1D(filters=24, kernel_size=3, padding='same', activation=tf.nn.relu)(bn1)\n",
    "    conv4 = layers.Conv1D(filters=6, kernel_size=3, padding='same', activation=tf.nn.relu)(conv3)\n",
    "    bn2 = layers.BatchNormalization()(conv4)\n",
    "    \n",
    "    lstm1 = layers.LSTM(16, return_sequences=True)(bn2)\n",
    "    dropout = layers.Dropout(0.25)(lstm1)\n",
    "    lstm2 = layers.LSTM(16, return_sequences=False)(dropout)\n",
    "    dropout2 = layers.Dropout(0.25)(lstm2)\n",
    "    dense1 = layers.Dense(32, activation=tf.nn.relu)(dropout2)\n",
    "\n",
    "    outputs = layers.Dense(len(train_labels.keys()), activation=None)(dense1)\n",
    "    \n",
    "    model = models.Model(inputs=path_inputs, outputs=outputs)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', \n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sj49Og4YGULr"
   },
   "source": [
    "### Inspect the model\n",
    "\n",
    "Use the `.summary` method to print a simple description of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ReAD0n6MsFK-"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vt6W50qGsJAL"
   },
   "source": [
    "\n",
    "Now try out the model. Take a batch of `4` examples from the training data and call `model.predict` on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-d-gBaVtGTSC"
   },
   "outputs": [],
   "source": [
    "example_batch = train_paths_as_array[:4]\n",
    "example_result = model.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0-qWCsh6DlyH"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "Train the model for up to 500 epochs with the training set, and record the training and validation accuracy in the `history` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sD7qHCmNIOY0"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                                 patience=10, min_lr=0.01*learning_rate)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=1, \n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "callbacks = [reduce_lr, early_stopping]\n",
    "\n",
    "\n",
    "history = model.fit(train_paths_as_array, \n",
    "                    train_labels.values,\n",
    "                    epochs=EPOCHS, validation_split=0.2, verbose=1,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQm3pc0FYPQB"
   },
   "source": [
    "Visualize the model's training progress using the stats stored in the `history` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Xj91b-dymEy"
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6XriGbVPh2t"
   },
   "outputs": [],
   "source": [
    "utils.plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ft603OzXuEZC"
   },
   "source": [
    "As our data set of real GPX tracks is very small, the optimal choice of the epoch for ending training depends on the distribution of tracks between training, validation and testing data. The above choice led to quite stable results. The model trains quite well and is slightly better than the simple model discussed in the other notebook.\n",
    "\n",
    "\n",
    "### Make predictions\n",
    "\n",
    "Finally, predict walking time values using data in the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xe7RXH3N3CWU"
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_paths_as_array)\n",
    "\n",
    "utils.scatter_plot(test_labels[\"MovingTime\"].values, test_predictions, \"Moving time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OrkHGKZcusUo"
   },
   "source": [
    "It looks like our model predicts durations and moving times reasonably well, as the results should be as close to the diagonal as possible. There are interesting gaps in the plots at low times. Let's take a look at the error distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_error_hist(test_labels[\"MovingTime\"].values, test_predictions[:, 0], \"Moving time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9_kI6MHu1UU"
   },
   "source": [
    "It's not quite gaussian, but we might expect that because the number of samples is very small.\n",
    "\n",
    "Export model for use in inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_hikingTimePrediction_recurrent.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of predictions with standard formula for predicting hiking durations\n",
    "\n",
    "In the following, the predictions are compared with the estimates for hiking durations from a standard formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_standard_walking_time_vectorized = np.vectorize(utils.compute_standard_walking_time)\n",
    "\n",
    "standard_estimate_walking_time = compute_standard_walking_time_vectorized(test_dataset['Length2d'].values,\n",
    "                                                                          test_dataset['TotalUphill'].values,\n",
    "                                                                          test_dataset['TotalDownhill'].values)\n",
    "\n",
    "utils.scatter_plot(test_predictions[:, 0], standard_estimate_walking_time, 'Standard estimate for duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_error_hist(test_predictions[:, 0], \n",
    "                      standard_estimate_walking_time, \n",
    "                      'Standard estimate for duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgGQuV-yqYZH"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook presents the training of an algorithm for predicting moving and stopping times as well as total duration for hiking (but it can also be applied to many other outdoor activities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_paths_as_array, test_labels, return_dict=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'loss': 370.7421569824219,\n",
    " 'mean_absolute_error': 13.343374252319336,\n",
    " 'mean_squared_error': 370.7421569824219}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "basic_regression.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
